#!/usr/bin/env python3
"""
Download marathon data from Google Sheets and convert to GeoJSON format.
This script automatically downloads the latest data and updates the public GeoJSON file.
"""

import csv
import json
import requests
import sys
from datetime import datetime

# Google Sheets CSV URL
GOOGLE_SHEET_URL = "https://docs.google.com/spreadsheets/d/e/2PACX-1vSDhMx8shcqFiqMKjLnrC0NNhV3b_kNCyn7FfpT0IYd8gPJf0VnKtgkGSmtJRWzbTaLR1LtSeMnmwny/pub?gid=190506599&single=true&output=csv"

def clean_coordinate(coord_str):
    """Clean and convert coordinate string to float."""
    if not coord_str or coord_str.strip() == '':
        return None
    
    # Replace unicode minus signs with regular minus
    coord_str = coord_str.replace('‚àí', '-')
    
    try:
        return float(coord_str.strip())
    except ValueError:
        return None

def clean_text(text):
    """Clean text by removing extra whitespace and handling encoding."""
    if not text:
        return ""
    
    # Handle common encoding issues
    text = text.replace('√¢', '-')   # Fix specific "√¢" character to hyphen
    text = text.replace('√É¬©', '√©')  # Fix √© character
    text = text.replace('√É¬®', '√®')  # Fix √® character  
    text = text.replace('√É¬°', '√°')  # Fix √° character
    text = text.replace('√É¬≠', '√≠')  # Fix √≠ character
    text = text.replace('√É¬≥', '√≥')  # Fix √≥ character
    text = text.replace('√É¬º', '√º')  # Fix √º character
    text = text.replace('√É¬±', '√±')  # Fix √± character
    text = text.replace('√É¬ß', '√ß')  # Fix √ß character
    text = text.replace('√¢‚Ç¨‚Ñ¢', "'")  # Fix apostrophe
    text = text.replace('√¢‚Ç¨≈ì', '"')  # Fix left quote
    text = text.replace('√¢‚Ç¨', '"')   # Fix right quote
    text = text.replace('√¢‚Ç¨"', '‚Äì')  # Fix en dash
    text = text.replace('√¢‚Ç¨"', '‚Äî')  # Fix em dash
    
    return text.strip()

def parse_date(date_str):
    """Parse date string to ISO format."""
    if not date_str or date_str.strip() == '':
        return None
    
    date_str = date_str.strip()
    
    # Handle various date formats
    try:
        # Try DD/MM/YYYY format first
        if '/' in date_str:
            parts = date_str.split('/')
            if len(parts) == 3:
                day, month, year = parts
                return f"{year}-{month.zfill(2)}-{day.zfill(2)}"
        
        # Try other formats as needed
        return date_str
    except:
        return date_str

def download_and_convert():
    """Download CSV from Google Sheets and convert to GeoJSON."""
    
    print("Downloading marathon data from Google Sheets...")
    
    try:
        # Download CSV data
        response = requests.get(GOOGLE_SHEET_URL)
        response.raise_for_status()
        
        # Parse CSV
        csv_content = response.text
        csv_reader = csv.DictReader(csv_content.splitlines())
        
        features = []
        skipped_count = 0
        processed_count = 0
        
        for row_num, row in enumerate(csv_reader, start=2):  # Start at 2 since header is row 1
            # Skip if show? is not TRUE
            show_value = row.get('show?', '').strip().upper()
            if show_value != 'TRUE':
                skipped_count += 1
                continue
            
            # Get coordinates
            lat_str = row.get('lat', '').strip()
            lon_str = row.get('lon', '').strip()
            
            lat = clean_coordinate(lat_str)
            lon = clean_coordinate(lon_str)
            
            # Skip if coordinates are invalid
            if lat is None or lon is None:
                skipped_count += 1
                print(f"Row {row_num}: Skipping due to invalid coordinates: lat='{lat_str}', lon='{lon_str}'")
                continue
            
            # Skip if essential fields are missing
            name = clean_text(row.get('Name', ''))
            city = clean_text(row.get('City', ''))
            
            if not name or name == '#REF!' or not city or city == '#REF!':
                skipped_count += 1
                print(f"Row {row_num}: Skipping due to missing/invalid name or city")
                continue
            
            # Create feature
            feature = {
                "type": "Feature",
                "geometry": {
                    "type": "Point",
                    "coordinates": [lon, lat]
                },
                "properties": {
                    "type": "marathon",
                    "name": name,
                    "city": city,
                    "country_iso": clean_text(row.get('ISO3', '')),
                    "year": clean_text(row.get('Year', '')),
                    "marathon_type": clean_text(row.get('Full / Half', '')),
                    "date": parse_date(row.get('Date', '')),
                    "signup_deadline": parse_date(row.get('Sign up deadlines', '')),
                    "availability": clean_text(row.get('Availability', '')),
                    "landing_page": clean_text(row.get('Landing Page', '')),
                    "google_ads": clean_text(row.get('Google Ads', '')),
                    "comments": clean_text(row.get('Comments', '')),
                    "map_info_text": clean_text(row.get('Map Info Text', ''))
                }
            }
            
            features.append(feature)
            processed_count += 1
        
        # Create GeoJSON structure
        geojson = {
            "type": "FeatureCollection",
            "features": features,
            "metadata": {
                "last_updated": datetime.now().isoformat(),
                "source": "Google Sheets",
                "total_features": len(features)
            }
        }
        
        # Write to file
        output_file = "data/marathons.geojson"
        with open(output_file, 'w', encoding='utf-8') as geojsonfile:
            json.dump(geojson, geojsonfile, indent=2, ensure_ascii=False)
        
        print(f"‚úÖ Marathon data conversion complete!")
        print(f"üìä Processed: {processed_count} marathons")
        print(f"‚è≠Ô∏è  Skipped: {skipped_count} records")
        print(f"üìÅ Output: {output_file}")
        print(f"üïí Last updated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        return True
        
    except requests.RequestException as e:
        print(f"‚ùå Error downloading data: {e}")
        return False
    except Exception as e:
        print(f"‚ùå Error processing data: {e}")
        return False

if __name__ == "__main__":
    success = download_and_convert()
    sys.exit(0 if success else 1)
